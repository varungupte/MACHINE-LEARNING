{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "eps = np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nodestructure:\n",
    "    def __init__(self, value, pos=0, neg=0, left=None, right=None):\n",
    "        self.value=value\n",
    "        self.left=left\n",
    "        self.right=right\n",
    "        self.positive=pos\n",
    "        self.negative=neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "left=df['left']\n",
    "df=df.drop(columns=['left'])\n",
    "df = pd.concat([df,pd.get_dummies(df['sales'], prefix='sales')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['salary'], prefix='salary')],axis=1)\n",
    "df.drop(['sales','salary'],axis=1, inplace=True)\n",
    "df=df.join(left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericalfeatures = ['number_project','last_evaluation','satisfaction_level','average_montly_hours','time_spend_company']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(df)) < 0.8\n",
    "train = df[msk]\n",
    "test = df[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def giniprediction(train,test):\n",
    "    mid_point={}\n",
    "    def find_entropy(df):\n",
    "        target = df.keys()[-1]   \n",
    "        entropy = 0\n",
    "        values = df[target].unique()\n",
    "        for value in values:\n",
    "            fraction = df[target].value_counts()[value]/(len(df[target])+eps)\n",
    "            entropy += fraction*fraction\n",
    "        return entropy  \n",
    "    \n",
    "    def find_entropy_attribute(df,attribute):\n",
    "        target = df.keys()[-1]   \n",
    "        #Will return the unique values present in the target column 'left'\n",
    "        target_variables = df[target].unique() \n",
    "        variables = df[attribute].unique()\n",
    "        entropy2 = 0\n",
    "        for variable in variables:\n",
    "            entropy = 0\n",
    "            for target_variable in target_variables:\n",
    "                num = len(df[attribute][df[attribute]==variable][df[target] ==target_variable])\n",
    "                den = len(df[attribute][df[attribute]==variable])\n",
    "                fraction = num/(den+eps)\n",
    "                entropy += fraction*fraction\n",
    "            fraction2 =(den)/len(df)\n",
    "            entropy2 += fraction2*entropy\n",
    "        return abs(entropy2)\n",
    "\n",
    "    def get_subtable1(X_train,node,value):\n",
    "        return X_train[X_train[node] < value].reset_index(drop=True)\n",
    "    \n",
    "    def get_subtable2(X_train,node,value):\n",
    "        return X_train[X_train[node] >= value].reset_index(drop=True)\n",
    "    \n",
    "    def find_winner(df):\n",
    "        Entropy_att = []\n",
    "        IG = []\n",
    "        for key in df.keys()[:-1]:       \n",
    "            IG.append(find_entropy(df)-find_entropy_attribute(df,key))\n",
    "        return df.keys()[:-1][np.argmax(IG)]\n",
    "\n",
    "    def get_subtable(df,node,value):\n",
    "        return df[df[node] == value].reset_index(drop=True)\n",
    "    \n",
    "    for feature in numericalfeatures:\n",
    "        IGMax=0\n",
    "        midmax=0\n",
    "        prev=None\n",
    "        train.sort_values(feature,inplace=True)\n",
    "        for index,row in train.iterrows():\n",
    "            if prev is not None:\n",
    "                if prev['left']!=row['left']:\n",
    "                    mid=(float(prev[feature])+float(row[feature]))/2\n",
    "                    subtable1=get_subtable1(train,feature,mid)\n",
    "                    subtable2=get_subtable2(train,feature,mid)\n",
    "                    firstentropy=0\n",
    "                    secondentropy=0\n",
    "                    if subtable1.empty:\n",
    "                        firstentropy=0\n",
    "                    else:\n",
    "                        frac1=float(len(subtable1))/len(train)\n",
    "                        firstentropy = frac1*find_entropy(subtable1)\n",
    "                    if subtable2.empty:\n",
    "                        secondentropy=0\n",
    "                    else:\n",
    "                        frac2=float(len(subtable2))/len(train)\n",
    "                        secondentropy = frac2*find_entropy(subtable2)\n",
    "\n",
    "                    entropy1=find_entropy(train)\n",
    "                    entropy2=firstentropy+secondentropy\n",
    "                    ig=abs(entropy1)-abs(entropy2)\n",
    "                    if ig > IGMax:\n",
    "                        IGMax=ig\n",
    "                        midmax=mid\n",
    "\n",
    "            prev=row\n",
    "        mid_point[feature]=midmax\n",
    "        for index,row in train.iterrows():\n",
    "            if float(row[feature])>=midmax:\n",
    "                train.at[index,feature]=1\n",
    "            else:\n",
    "                train.at[index,feature]=0\n",
    "            \n",
    "            \n",
    "    def buildtree(train):\n",
    "        if len(train.columns)==1:\n",
    "            return None\n",
    "        output=train.keys()[-1]\n",
    "        node= find_winner(train)\n",
    "        root=nodestructure(node)\n",
    "        outputValue,counts = np.unique(train[output],return_counts=True)                        \n",
    "        if len(counts)<=1:\n",
    "            if outputValue[0]==0:\n",
    "                root.negative=counts[0]\n",
    "            else:\n",
    "                root.positive=counts[0]\n",
    "        else:\n",
    "            if outputValue[1]==0:\n",
    "                root.negative=counts[1]\n",
    "            else:\n",
    "                root.positive=counts[1]\n",
    "            if outputValue[0]==0:\n",
    "                root.negative=counts[0]\n",
    "            else:\n",
    "                root.positive=counts[0]\n",
    "            attValue=train[node].unique()\n",
    "            for val in attValue:\n",
    "                subdataframe = get_subtable(train,node,val)                     \n",
    "                subdataframe=subdataframe.drop([node],axis=1)\n",
    "                outputValue,counts = np.unique(subdataframe[output],return_counts=True)                        \n",
    "                if len(counts)<=1:\n",
    "                    pass\n",
    "                else:\n",
    "                    if val == 1:\n",
    "                        root.right = buildtree(subdataframe)\n",
    "                    else:\n",
    "                        root.left = buildtree(subdataframe)\n",
    "\n",
    "        return root\n",
    "    \n",
    "    rootNode=buildtree(train)\n",
    "#     print rootNode.value\n",
    "#     print rootNode.left.value\n",
    "#     print rootNode.right.value\n",
    "    \n",
    "    def testing(X_test,root):\n",
    "    \n",
    "        if root.left == None and root.right == None:\n",
    "            if root.positive>root.negative:\n",
    "                y_pred.append(1)\n",
    "            else:\n",
    "                y_pred.append(0)\n",
    "            return\n",
    "\n",
    "        j = root.value\n",
    "        if j in X_test:\n",
    "            if X_test[j] == 1:\n",
    "                if root.right==None:\n",
    "                    if root.positive>root.negative:\n",
    "                        y_pred.append(1)\n",
    "                    else:\n",
    "                        y_pred.append(0)\n",
    "                else:\n",
    "                    testing(X_test,root.right)\n",
    "            else:\n",
    "                if root.left==None:\n",
    "                    if root.positive>root.negative:\n",
    "                        y_pred.append(1)\n",
    "                    else:\n",
    "                        y_pred.append(0)\n",
    "                else:\n",
    "                    testing(X_test,root.left)\n",
    "        else:\n",
    "            if root.left==None:\n",
    "                if root.positive>root.negative:\n",
    "                    y_pred.append(1)\n",
    "                else:\n",
    "                    y_pred.append(0)\n",
    "            else:\n",
    "                testing(X_test,root.left)\n",
    "    \n",
    "    def convert_to_binary(X_test):\n",
    "        for feature in numericalfeatures:\n",
    "            for index,row in X_test.iterrows():\n",
    "                if float(row[feature]) >= mid_point[feature]:\n",
    "                    X_test.at[index,feature]=1\n",
    "                else:\n",
    "                    X_test.at[index,feature]=0\n",
    "\n",
    "    y_pred=[]\n",
    "\n",
    "    # X_test1 = pd.read_csv(\"sample_test.csv\")\n",
    "    # X_test1 = pd.concat([X_test1,pd.get_dummies(X_test1['sales'], prefix='sales')],axis=1)\n",
    "    # X_test1 = pd.concat([X_test1,pd.get_dummies(X_test1['salary'], prefix='salary')],axis=1)\n",
    "    # X_test1.drop(['sales','salary'],axis=1, inplace=True)\n",
    "\n",
    "    Y_test=test['left']\n",
    "    X_test=test.drop(['left'],axis=1)\n",
    "    # X_test\n",
    "    convert_to_binary(X_test)\n",
    "\n",
    "    for index,row in X_test.iterrows():\n",
    "        testing(row,rootNode)\n",
    "\n",
    "    # print y_pred\n",
    "\n",
    "    print confusion_matrix(Y_test,y_pred)\n",
    "    print classification_report(Y_test,y_pred)\n",
    "    print accuracy_score(Y_test, y_pred)\n",
    "    return rootNode,mid_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def misclassificationprediction(train,test):\n",
    "    mid_point={}\n",
    "    def find_entropy(df):\n",
    "        target = df.keys()[-1]   \n",
    "        entropy = 1\n",
    "        values = df[target].unique()\n",
    "        for value in values:\n",
    "            fraction = df[target].value_counts()[value]/(len(df[target])+eps)\n",
    "            entropy = min(fraction,entropy)\n",
    "        return entropy  \n",
    "    \n",
    "    def find_entropy_attribute(df,attribute):\n",
    "        target = df.keys()[-1]   \n",
    "        #Will return the unique values present in the target column 'left'\n",
    "        target_variables = df[target].unique() \n",
    "        variables = df[attribute].unique()\n",
    "        entropy2 = 0\n",
    "        for variable in variables:\n",
    "            entropy = 1\n",
    "            for target_variable in target_variables:\n",
    "                num = len(df[attribute][df[attribute]==variable][df[target] ==target_variable])\n",
    "                den = len(df[attribute][df[attribute]==variable])\n",
    "                fraction = num/(den+eps)\n",
    "                entropy =min(fraction,entropy)\n",
    "            fraction2 =(den)/len(df)\n",
    "            entropy2 += fraction2*entropy\n",
    "        return abs(entropy2)\n",
    "\n",
    "    def get_subtable1(X_train,node,value):\n",
    "        return X_train[X_train[node] < value].reset_index(drop=True)\n",
    "    \n",
    "    def get_subtable2(X_train,node,value):\n",
    "        return X_train[X_train[node] >= value].reset_index(drop=True)\n",
    "    \n",
    "    def find_winner(df):\n",
    "        Entropy_att = []\n",
    "        IG = []\n",
    "        for key in df.keys()[:-1]:       \n",
    "            IG.append(find_entropy(df)-find_entropy_attribute(df,key))\n",
    "        return df.keys()[:-1][np.argmax(IG)]\n",
    "\n",
    "    def get_subtable(df,node,value):\n",
    "        return df[df[node] == value].reset_index(drop=True)\n",
    "    \n",
    "    for feature in numericalfeatures:\n",
    "        IGMax=0\n",
    "        midmax=0\n",
    "        prev=None\n",
    "        train.sort_values(feature,inplace=True)\n",
    "        for index,row in train.iterrows():\n",
    "            if prev is not None:\n",
    "                if prev['left']!=row['left']:\n",
    "                    mid=(float(prev[feature])+float(row[feature]))/2\n",
    "                    subtable1=get_subtable1(train,feature,mid)\n",
    "                    subtable2=get_subtable2(train,feature,mid)\n",
    "                    firstentropy=0\n",
    "                    secondentropy=0\n",
    "                    if subtable1.empty:\n",
    "                        firstentropy=0\n",
    "                    else:\n",
    "                        frac1=float(len(subtable1))/len(train)\n",
    "                        firstentropy = frac1*find_entropy(subtable1)\n",
    "                    if subtable2.empty:\n",
    "                        secondentropy=0\n",
    "                    else:\n",
    "                        frac2=float(len(subtable2))/len(train)\n",
    "                        secondentropy = frac2*find_entropy(subtable2)\n",
    "\n",
    "                    entropy1=find_entropy(train)\n",
    "                    entropy2=firstentropy+secondentropy\n",
    "                    ig=abs(entropy1)-abs(entropy2)\n",
    "                    if ig > IGMax:\n",
    "                        IGMax=ig\n",
    "                        midmax=mid\n",
    "\n",
    "            prev=row\n",
    "        mid_point[feature]=midmax\n",
    "        for index,row in train.iterrows():\n",
    "            if float(row[feature])>=midmax:\n",
    "                train.at[index,feature]=1\n",
    "            else:\n",
    "                train.at[index,feature]=0\n",
    "            \n",
    "            \n",
    "    def buildtree(train):\n",
    "        if len(train.columns)==1:\n",
    "            return None\n",
    "        output=train.keys()[-1]\n",
    "        node= find_winner(train)\n",
    "        root=nodestructure(node)\n",
    "        outputValue,counts = np.unique(train[output],return_counts=True)                        \n",
    "        if len(counts)<=1:\n",
    "            if outputValue[0]==0:\n",
    "                root.negative=counts[0]\n",
    "            else:\n",
    "                root.positive=counts[0]\n",
    "        else:\n",
    "            if outputValue[1]==0:\n",
    "                root.negative=counts[1]\n",
    "            else:\n",
    "                root.positive=counts[1]\n",
    "            if outputValue[0]==0:\n",
    "                root.negative=counts[0]\n",
    "            else:\n",
    "                root.positive=counts[0]\n",
    "            attValue=train[node].unique()\n",
    "            for val in attValue:\n",
    "                subdataframe = get_subtable(train,node,val)                     \n",
    "                subdataframe=subdataframe.drop([node],axis=1)\n",
    "                outputValue,counts = np.unique(subdataframe[output],return_counts=True)                        \n",
    "                if len(counts)<=1:\n",
    "                    pass\n",
    "                else:\n",
    "                    if val == 1:\n",
    "                        root.right = buildtree(subdataframe)\n",
    "                    else:\n",
    "                        root.left = buildtree(subdataframe)\n",
    "\n",
    "        return root\n",
    "    \n",
    "    rootNode=buildtree(train)\n",
    "#     print rootNode.value\n",
    "#     print rootNode.left.value\n",
    "#     print rootNode.right.value\n",
    "    \n",
    "    def testing(X_test,root):\n",
    "    \n",
    "        if root.left == None and root.right == None:\n",
    "            if root.positive>root.negative:\n",
    "                y_pred.append(1)\n",
    "            else:\n",
    "                y_pred.append(0)\n",
    "            return\n",
    "\n",
    "        j = root.value\n",
    "        if j in X_test:\n",
    "            if X_test[j] == 1:\n",
    "                if root.right==None:\n",
    "                    if root.positive>root.negative:\n",
    "                        y_pred.append(1)\n",
    "                    else:\n",
    "                        y_pred.append(0)\n",
    "                else:\n",
    "                    testing(X_test,root.right)\n",
    "            else:\n",
    "                if root.left==None:\n",
    "                    if root.positive>root.negative:\n",
    "                        y_pred.append(1)\n",
    "                    else:\n",
    "                        y_pred.append(0)\n",
    "                else:\n",
    "                    testing(X_test,root.left)\n",
    "        else:\n",
    "            if root.left==None:\n",
    "                if root.positive>root.negative:\n",
    "                    y_pred.append(1)\n",
    "                else:\n",
    "                    y_pred.append(0)\n",
    "            else:\n",
    "                testing(X_test,root.left)\n",
    "    \n",
    "    def convert_to_binary(X_test):\n",
    "        for feature in numericalfeatures:\n",
    "            for index,row in X_test.iterrows():\n",
    "                if float(row[feature]) >= mid_point[feature]:\n",
    "                    X_test.at[index,feature]=1\n",
    "                else:\n",
    "                    X_test.at[index,feature]=0\n",
    "\n",
    "    y_pred=[]\n",
    "\n",
    "    # X_test1 = pd.read_csv(\"sample_test.csv\")\n",
    "    # X_test1 = pd.concat([X_test1,pd.get_dummies(X_test1['sales'], prefix='sales')],axis=1)\n",
    "    # X_test1 = pd.concat([X_test1,pd.get_dummies(X_test1['salary'], prefix='salary')],axis=1)\n",
    "    # X_test1.drop(['sales','salary'],axis=1, inplace=True)\n",
    "\n",
    "    Y_test=test['left']\n",
    "    X_test=test.drop(['left'],axis=1)\n",
    "    # X_test\n",
    "    convert_to_binary(X_test)\n",
    "\n",
    "    for index,row in X_test.iterrows():\n",
    "        testing(row,rootNode)\n",
    "\n",
    "    # print y_pred\n",
    "\n",
    "    print confusion_matrix(Y_test,y_pred)\n",
    "    print classification_report(Y_test,y_pred)\n",
    "    print accuracy_score(Y_test, y_pred)\n",
    "    return rootNode,mid_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropyprediction(train,test):\n",
    "    mid_point={}\n",
    "    def find_entropy(df):\n",
    "        target = df.keys()[-1]   \n",
    "        entropy = 0\n",
    "        values = df[target].unique()\n",
    "        for value in values:\n",
    "            fraction = df[target].value_counts()[value]/(len(df[target])+eps)\n",
    "            entropy += -fraction*np.log2(fraction+eps)\n",
    "        return entropy  \n",
    "    \n",
    "    def find_entropy_attribute(df,attribute):\n",
    "        target = df.keys()[-1]   \n",
    "        #Will return the unique values present in the target column 'left'\n",
    "        target_variables = df[target].unique() \n",
    "        variables = df[attribute].unique()\n",
    "        entropy2 = 0\n",
    "        for variable in variables:\n",
    "            entropy = 0\n",
    "            for target_variable in target_variables:\n",
    "                num = len(df[attribute][df[attribute]==variable][df[target] ==target_variable])\n",
    "                den = len(df[attribute][df[attribute]==variable])\n",
    "                fraction = num/(den+eps)\n",
    "                entropy += -fraction*np.log2(fraction+eps)\n",
    "            fraction2 =(den)/len(df)\n",
    "            entropy2 += -fraction2*entropy\n",
    "        return abs(entropy2)\n",
    "\n",
    "    def get_subtable1(X_train,node,value):\n",
    "        return X_train[X_train[node] < value].reset_index(drop=True)\n",
    "    \n",
    "    def get_subtable2(X_train,node,value):\n",
    "        return X_train[X_train[node] >= value].reset_index(drop=True)\n",
    "    \n",
    "    def find_winner(df):\n",
    "        Entropy_att = []\n",
    "        IG = []\n",
    "        for key in df.keys()[:-1]:       \n",
    "            IG.append(find_entropy(df)-find_entropy_attribute(df,key))\n",
    "        return df.keys()[:-1][np.argmax(IG)]\n",
    "\n",
    "    def get_subtable(df,node,value):\n",
    "        return df[df[node] == value].reset_index(drop=True)\n",
    "    \n",
    "    for feature in numericalfeatures:\n",
    "        IGMax=0\n",
    "        midmax=0\n",
    "        prev=None\n",
    "        train.sort_values(feature,inplace=True)\n",
    "        for index,row in train.iterrows():\n",
    "            if prev is not None:\n",
    "                if prev['left']!=row['left']:\n",
    "                    mid=(float(prev[feature])+float(row[feature]))/2\n",
    "                    subtable1=get_subtable1(train,feature,mid)\n",
    "                    subtable2=get_subtable2(train,feature,mid)\n",
    "                    firstentropy=0\n",
    "                    secondentropy=0\n",
    "                    if subtable1.empty:\n",
    "                        firstentropy=0\n",
    "                    else:\n",
    "                        frac1=float(len(subtable1))/len(train)\n",
    "                        firstentropy = frac1*find_entropy(subtable1)\n",
    "                    if subtable2.empty:\n",
    "                        secondentropy=0\n",
    "                    else:\n",
    "                        frac2=float(len(subtable2))/len(train)\n",
    "                        secondentropy = frac2*find_entropy(subtable2)\n",
    "\n",
    "                    entropy1=find_entropy(train)\n",
    "                    entropy2=firstentropy+secondentropy\n",
    "                    ig=abs(entropy1)-abs(entropy2)\n",
    "                    if ig > IGMax:\n",
    "                        IGMax=ig\n",
    "                        midmax=mid\n",
    "\n",
    "            prev=row\n",
    "        mid_point[feature]=midmax\n",
    "        for index,row in train.iterrows():\n",
    "            if float(row[feature])>=midmax:\n",
    "                train.at[index,feature]=1\n",
    "            else:\n",
    "                train.at[index,feature]=0\n",
    "            \n",
    "            \n",
    "    def buildtree(train):\n",
    "        if len(train.columns)==1:\n",
    "            return None\n",
    "        output=train.keys()[-1]\n",
    "        node= find_winner(train)\n",
    "        root=nodestructure(node)\n",
    "        outputValue,counts = np.unique(train[output],return_counts=True)                        \n",
    "        if len(counts)<=1:\n",
    "            if outputValue[0]==0:\n",
    "                root.negative=counts[0]\n",
    "            else:\n",
    "                root.positive=counts[0]\n",
    "        else:\n",
    "            if outputValue[1]==0:\n",
    "                root.negative=counts[1]\n",
    "            else:\n",
    "                root.positive=counts[1]\n",
    "            if outputValue[0]==0:\n",
    "                root.negative=counts[0]\n",
    "            else:\n",
    "                root.positive=counts[0]\n",
    "            attValue=train[node].unique()\n",
    "            for val in attValue:\n",
    "                subdataframe = get_subtable(train,node,val)                     \n",
    "                subdataframe=subdataframe.drop([node],axis=1)\n",
    "                outputValue,counts = np.unique(subdataframe[output],return_counts=True)                        \n",
    "                if len(counts)<=1:\n",
    "                    pass\n",
    "                else:\n",
    "                    if val == 1:\n",
    "                        root.right = buildtree(subdataframe)\n",
    "                    else:\n",
    "                        root.left = buildtree(subdataframe)\n",
    "\n",
    "        return root\n",
    "    \n",
    "    rootNode=buildtree(train)\n",
    "    print rootNode.value\n",
    "    print rootNode.left.value\n",
    "    print rootNode.right.value\n",
    "    \n",
    "    def testing(X_test,root):\n",
    "    \n",
    "        if root.left == None and root.right == None:\n",
    "            if root.positive>root.negative:\n",
    "                y_pred.append(1)\n",
    "            else:\n",
    "                y_pred.append(0)\n",
    "            return\n",
    "\n",
    "        j = root.value\n",
    "        if j in X_test:\n",
    "            if X_test[j] == 1:\n",
    "                if root.right==None:\n",
    "                    if root.positive>root.negative:\n",
    "                        y_pred.append(1)\n",
    "                    else:\n",
    "                        y_pred.append(0)\n",
    "                else:\n",
    "                    testing(X_test,root.right)\n",
    "            else:\n",
    "                if root.left==None:\n",
    "                    if root.positive>root.negative:\n",
    "                        y_pred.append(1)\n",
    "                    else:\n",
    "                        y_pred.append(0)\n",
    "                else:\n",
    "                    testing(X_test,root.left)\n",
    "        else:\n",
    "            if root.left==None:\n",
    "                if root.positive>root.negative:\n",
    "                    y_pred.append(1)\n",
    "                else:\n",
    "                    y_pred.append(0)\n",
    "            else:\n",
    "                testing(X_test,root.left)\n",
    "    \n",
    "    def convert_to_binary(X_test):\n",
    "        for feature in numericalfeatures:\n",
    "            for index,row in X_test.iterrows():\n",
    "                if float(row[feature]) >= mid_point[feature]:\n",
    "                    X_test.at[index,feature]=1\n",
    "                else:\n",
    "                    X_test.at[index,feature]=0\n",
    "\n",
    "    y_pred=[]\n",
    "    Y_test=test['left']\n",
    "    X_test=test.drop(['left'],axis=1)\n",
    "    # X_test\n",
    "    convert_to_binary(X_test)\n",
    "\n",
    "    for index,row in X_test.iterrows():\n",
    "        testing(row,rootNode)\n",
    "\n",
    "    # print y_pred\n",
    "\n",
    "    print confusion_matrix(Y_test,y_pred)\n",
    "    print classification_report(Y_test,y_pred)\n",
    "    print accuracy_score(Y_test, y_pred)\n",
    "    return mid_point,rootNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictentropy(rootNode,mid_point,test):\n",
    "    def testing(X_test,root):\n",
    "        if root.left == None and root.right == None:\n",
    "            if root.positive>root.negative:\n",
    "                y_pred.append(1)\n",
    "            else:\n",
    "                y_pred.append(0)\n",
    "            return\n",
    "\n",
    "        j = root.value\n",
    "        if j in X_test:\n",
    "            if X_test[j] == 1:\n",
    "                if root.right==None:\n",
    "                    if root.positive>root.negative:\n",
    "                        y_pred.append(1)\n",
    "                    else:\n",
    "                        y_pred.append(0)\n",
    "                else:\n",
    "                    testing(X_test,root.right)\n",
    "            else:\n",
    "                if root.left==None:\n",
    "                    if root.positive>root.negative:\n",
    "                        y_pred.append(1)\n",
    "                    else:\n",
    "                        y_pred.append(0)\n",
    "                else:\n",
    "                    testing(X_test,root.left)\n",
    "        else:\n",
    "            if root.left==None:\n",
    "                if root.positive>root.negative:\n",
    "                    y_pred.append(1)\n",
    "                else:\n",
    "                    y_pred.append(0)\n",
    "            else:\n",
    "                testing(X_test,root.left)\n",
    "    \n",
    "    def convert_to_binary(X_test):\n",
    "        for feature in numericalfeatures:\n",
    "            for index,row in X_test.iterrows():\n",
    "                if float(row[feature]) >= mid_point[feature]:\n",
    "                    X_test.at[index,feature]=1\n",
    "                else:\n",
    "                    X_test.at[index,feature]=0\n",
    "\n",
    "    y_pred=[]\n",
    "    Y_test=test['left']\n",
    "    X_test=test.drop(['left'],axis=1)\n",
    "    convert_to_binary(X_test)\n",
    "    for index,row in X_test.iterrows():\n",
    "        testing(row,rootNode)\n",
    "    print confusion_matrix(Y_test,y_pred)\n",
    "    print classification_report(Y_test,y_pred)\n",
    "    print accuracy_score(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictgini(rootNode,mid_point,test):\n",
    "    def testing(X_test,root):\n",
    "        if root.left == None and root.right == None:\n",
    "            if root.positive>root.negative:\n",
    "                y_pred.append(1)\n",
    "            else:\n",
    "                y_pred.append(0)\n",
    "            return\n",
    "\n",
    "        j = root.value\n",
    "        if j in X_test:\n",
    "            if X_test[j] == 1:\n",
    "                if root.right==None:\n",
    "                    if root.positive>root.negative:\n",
    "                        y_pred.append(1)\n",
    "                    else:\n",
    "                        y_pred.append(0)\n",
    "                else:\n",
    "                    testing(X_test,root.right)\n",
    "            else:\n",
    "                if root.left==None:\n",
    "                    if root.positive>root.negative:\n",
    "                        y_pred.append(1)\n",
    "                    else:\n",
    "                        y_pred.append(0)\n",
    "                else:\n",
    "                    testing(X_test,root.left)\n",
    "        else:\n",
    "            if root.left==None:\n",
    "                if root.positive>root.negative:\n",
    "                    y_pred.append(1)\n",
    "                else:\n",
    "                    y_pred.append(0)\n",
    "            else:\n",
    "                testing(X_test,root.left)\n",
    "    \n",
    "    def convert_to_binary(X_test):\n",
    "        for feature in numericalfeatures:\n",
    "            for index,row in X_test.iterrows():\n",
    "                if float(row[feature]) >= mid_point[feature]:\n",
    "                    X_test.at[index,feature]=1\n",
    "                else:\n",
    "                    X_test.at[index,feature]=0\n",
    "\n",
    "    y_pred=[]\n",
    "    Y_test=test['left']\n",
    "    X_test=test.drop(['left'],axis=1)\n",
    "    convert_to_binary(X_test)\n",
    "    for index,row in X_test.iterrows():\n",
    "        testing(row,rootNode)\n",
    "    print confusion_matrix(Y_test,y_pred)\n",
    "    print classification_report(Y_test,y_pred)\n",
    "    print accuracy_score(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictmisclassification(rootNode,mid_point,test):\n",
    "    def testing(X_test,root):\n",
    "        if root.left == None and root.right == None:\n",
    "            if root.positive>root.negative:\n",
    "                y_pred.append(1)\n",
    "            else:\n",
    "                y_pred.append(0)\n",
    "            return\n",
    "\n",
    "        j = root.value\n",
    "        if j in X_test:\n",
    "            if X_test[j] == 1:\n",
    "                if root.right==None:\n",
    "                    if root.positive>root.negative:\n",
    "                        y_pred.append(1)\n",
    "                    else:\n",
    "                        y_pred.append(0)\n",
    "                else:\n",
    "                    testing(X_test,root.right)\n",
    "            else:\n",
    "                if root.left==None:\n",
    "                    if root.positive>root.negative:\n",
    "                        y_pred.append(1)\n",
    "                    else:\n",
    "                        y_pred.append(0)\n",
    "                else:\n",
    "                    testing(X_test,root.left)\n",
    "        else:\n",
    "            if root.left==None:\n",
    "                if root.positive>root.negative:\n",
    "                    y_pred.append(1)\n",
    "                else:\n",
    "                    y_pred.append(0)\n",
    "            else:\n",
    "                testing(X_test,root.left)\n",
    "    \n",
    "    def convert_to_binary(X_test):\n",
    "        for feature in numericalfeatures:\n",
    "            for index,row in X_test.iterrows():\n",
    "                if float(row[feature]) >= mid_point[feature]:\n",
    "                    X_test.at[index,feature]=1\n",
    "                else:\n",
    "                    X_test.at[index,feature]=0\n",
    "\n",
    "    y_pred=[]\n",
    "    Y_test=test['left']\n",
    "    X_test=test.drop(['left'],axis=1)\n",
    "    convert_to_binary(X_test)\n",
    "    for index,row in X_test.iterrows():\n",
    "        testing(row,rootNode)\n",
    "    print confusion_matrix(Y_test,y_pred)\n",
    "    print classification_report(Y_test,y_pred)\n",
    "    print accuracy_score(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vagupta/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "satisfaction_level\n",
      "last_evaluation\n",
      "last_evaluation\n",
      "[[1678   63]\n",
      " [ 178  309]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93      1741\n",
      "           1       0.83      0.63      0.72       487\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      2228\n",
      "   macro avg       0.87      0.80      0.83      2228\n",
      "weighted avg       0.89      0.89      0.89      2228\n",
      "\n",
      "0.8918312387791741\n"
     ]
    }
   ],
   "source": [
    "mid_point,model=entropyprediction(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         1\n",
      "   macro avg       1.00      1.00      1.00         1\n",
      "weighted avg       1.00      1.00      1.00         1\n",
      "\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# X_test1 = pd.read_csv(\"sample_test.csv\")\n",
    "# X_test1 = pd.concat([X_test1,pd.get_dummies(X_test1['sales'], prefix='sales')],axis=1)\n",
    "# X_test1 = pd.concat([X_test1,pd.get_dummies(X_test1['salary'], prefix='salary')],axis=1)\n",
    "# X_test1.drop(['sales','salary'],axis=1, inplace=True)\n",
    "# predictentropy(model,mid_point,X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vagupta/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1740    1]\n",
      " [ 486    1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88      1741\n",
      "           1       0.50      0.00      0.00       487\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      2228\n",
      "   macro avg       0.64      0.50      0.44      2228\n",
      "weighted avg       0.72      0.78      0.69      2228\n",
      "\n",
      "0.7814183123877917\n"
     ]
    }
   ],
   "source": [
    "model2,mid_point2=giniprediction(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [1 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.00      0.00      0.00         1\n",
      "   macro avg       0.00      0.00      0.00         1\n",
      "weighted avg       0.00      0.00      0.00         1\n",
      "\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vagupta/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# X_test1 = pd.read_csv(\"sample_test.csv\")\n",
    "# X_test1 = pd.concat([X_test1,pd.get_dummies(X_test1['sales'], prefix='sales')],axis=1)\n",
    "# X_test1 = pd.concat([X_test1,pd.get_dummies(X_test1['salary'], prefix='salary')],axis=1)\n",
    "# X_test1.drop(['sales','salary'],axis=1, inplace=True)\n",
    "# predictgini(model2,mid_point2,X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vagupta/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1740    1]\n",
      " [ 486    1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88      1741\n",
      "           1       0.50      0.00      0.00       487\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      2228\n",
      "   macro avg       0.64      0.50      0.44      2228\n",
      "weighted avg       0.72      0.78      0.69      2228\n",
      "\n",
      "0.7814183123877917\n"
     ]
    }
   ],
   "source": [
    "model3,mid_point3=misclassificationprediction(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test1 = pd.read_csv(\"sample_test.csv\")\n",
    "# X_test1 = pd.concat([X_test1,pd.get_dummies(X_test1['sales'], prefix='sales')],axis=1)\n",
    "# X_test1 = pd.concat([X_test1,pd.get_dummies(X_test1['salary'], prefix='salary')],axis=1)\n",
    "# X_test1.drop(['sales','salary'],axis=1, inplace=True)\n",
    "# predictmisclassification(model3,mid_point3,X_test1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
